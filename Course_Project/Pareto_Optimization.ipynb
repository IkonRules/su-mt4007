{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7bc4b74-5808-461c-9103-29d82d15a361",
   "metadata": {},
   "source": [
    "# Pareto optimization of event chains\n",
    "Program for analyzing the dataframe containing event chains and selecting Pareto optimal solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61d0dcdf-7a9e-4171-9bf3-6eb646634011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def load_simulation_output_df():\n",
    "    ''' Load the event chain simulation output. '''\n",
    "    simulation_output_df = pd.read_pickle('simulation_output_df.pkl')\n",
    "    \n",
    "    # Convert columns to str for hashing.\n",
    "    simulation_output_df['aggr_attack_type'] = simulation_output_df['aggr_attack_type'].astype(str)\n",
    "    simulation_output_df['aggr_attacking_nodes'] = simulation_output_df['aggr_attacking_nodes'].astype(str)\n",
    "    simulation_output_df['event_probs'] = simulation_output_df['event_probs'].astype(str)\n",
    "    \n",
    "    return simulation_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bab8b-8760-4f9c-8ca0-f7c843db5357",
   "metadata": {},
   "source": [
    "### Process the successful paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09665c61-1b8e-4a8e-a031-83ab82706ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_successful_paths(simulation_output_df):\n",
    "    ''' Select successful event chains, group by decisions and calculate metrics. '''\n",
    "    \n",
    "    # Select aggr_node_paths from pareto optimal list.\n",
    "    successful_outcomes = simulation_output_df[simulation_output_df['graph_conquered'] == True]\n",
    "    successful_paths_list = list(set(successful_outcomes['aggr_node_path']))\n",
    "    successful_paths_list\n",
    "    successful_paths_list_data = simulation_output_df[simulation_output_df['aggr_node_path'].isin(successful_paths_list)]\n",
    "\n",
    "    # Add node path aggregated probability mean to df.\n",
    "    successful_paths_list_data = successful_paths_list_data.copy()\n",
    "    path_and_attack_prob_mean = successful_paths_list_data.groupby('aggr_node_path')['aggr_prob'].mean().to_dict()\n",
    "    successful_paths_list_data['node_path_prob_mean'] = successful_paths_list_data['aggr_node_path'].map(path_and_attack_prob_mean)\n",
    "    successful_paths_list_data['success_weight'] = successful_paths_list_data.apply(\n",
    "        lambda row: row['aggr_prob'] / row['node_path_prob_mean'], axis=1)\n",
    "    successful_paths_list_data\n",
    "\n",
    "    # Calculate expected troop node values for node paths using probability weight.\n",
    "    def calculate_weighted_final_troops(group):\n",
    "        '''Calculate expected final troop numbers weighted by success weights.'''\n",
    "        weighted_sum = sum(group['success_weight'] * group['final_troop_numbers'].apply(lambda x: x['Player1']))\n",
    "        total_weight = group['success_weight'].sum()\n",
    "        return weighted_sum / total_weight if total_weight > 0 else 0\n",
    "    expected_troops_by_path = (\n",
    "        successful_paths_list_data.groupby('aggr_node_path')[['success_weight', 'final_troop_numbers']]\n",
    "        .apply(calculate_weighted_final_troops))\n",
    "    expected_troops_df = expected_troops_by_path.reset_index(name='expected_final_troops')\n",
    "\n",
    "    # Create success weight based on node path, attack type and attacking nodes.\n",
    "    successful_paths_list_data = successful_paths_list_data.copy()\n",
    "    path_and_attack_prob_mean = successful_paths_list_data.groupby(['aggr_node_path', 'aggr_attack_type', 'aggr_attacking_nodes'])['aggr_prob'].mean().to_dict()\n",
    "    successful_paths_list_data['path_and_attack_prob_mean'] = successful_paths_list_data.set_index(\n",
    "        ['aggr_node_path', 'aggr_attack_type', 'aggr_attacking_nodes']).index.map(path_and_attack_prob_mean)\n",
    "    successful_paths_list_data['success_weight'] = successful_paths_list_data.apply(\n",
    "        lambda row: row['aggr_prob'] / row['path_and_attack_prob_mean'], axis=1)\n",
    "    successful_paths_list_data\n",
    "\n",
    "    # Calculate expected troop numbers for the groups.\n",
    "    expected_troops_by_path_and_attack = (\n",
    "        successful_paths_list_data.groupby(['aggr_node_path', 'aggr_attack_type', 'aggr_attacking_nodes'])[['success_weight', 'final_troop_numbers']]\n",
    "        .apply(calculate_weighted_final_troops))\n",
    "    path_and_attack_exp_troops = expected_troops_by_path_and_attack.reset_index(name='expected_final_troops')\n",
    "    path_and_attack_exp_troops\n",
    "\n",
    "    # Calculate success mean based on node path AND attack type.\n",
    "    path_and_attack_prob_mean = successful_paths_list_data.groupby(['aggr_node_path', 'aggr_attack_type', 'aggr_attacking_nodes'])['aggr_prob'].mean().reset_index()\n",
    "\n",
    "    # Merge into df and save to pickle.\n",
    "    path_and_attack_properties_df = pd.merge(path_and_attack_prob_mean, path_and_attack_exp_troops, how='inner')\n",
    "    path_and_attack_properties_df.columns = ['Node path', 'Attack type', 'Attacking nodes', 'Success coefficient', 'Expected troop number']\n",
    "    path_and_attack_properties_df = path_and_attack_properties_df.sort_values(by='Success coefficient', ascending=False)\n",
    "    #path_and_attack_properties_df.to_pickle('path_and_attack_properties_df.pkl')\n",
    "    \n",
    "    return path_and_attack_properties_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c09577-15b4-40ea-a745-53c14f573949",
   "metadata": {},
   "source": [
    "### Pareto optimize\n",
    "Functions for calculating pareto fronts and collecting specified numbers of solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5aaabee-b1b3-45e4-a59e-571dcda087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_optimal(df, criteria1, criteria2):\n",
    "    ''' Identify pareto optimal rows. '''\n",
    "    pareto_front = []\n",
    "    for i, row in df.iterrows():\n",
    "        dominated = False\n",
    "        for i, other_row in df.iterrows():\n",
    "            \n",
    "            # Check if 'row' is dominated by 'other_row'.\n",
    "            if (other_row[criteria1] >= row[criteria1]\n",
    "                and other_row[criteria2] >= row[criteria2]\n",
    "                and (other_row[criteria1] > row[criteria1]\n",
    "                    or other_row[criteria2] > row[criteria2])):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            pareto_front.append(row)\n",
    "    \n",
    "    return pd.DataFrame(pareto_front)\n",
    "\n",
    "def collect_pareto_solutions(df, criteria1, criteria2, top_n):\n",
    "    ''' Collect n number of solutions starting from the top. '''\n",
    "    pareto_final = pd.DataFrame()\n",
    "    remaining_df = df.copy()\n",
    "\n",
    "    while len(pareto_final) < top_n and not remaining_df.empty:\n",
    "        pareto_front = pareto_optimal(remaining_df, criteria1, criteria2)\n",
    "        pareto_final = pd.concat([pareto_final, pareto_front])\n",
    "        remaining_df = remaining_df.drop(pareto_front.index)\n",
    "    pareto_final = pareto_final.head(top_n).reset_index(drop=True)\n",
    "    \n",
    "    return pareto_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b1e6026-2287-4afd-95a4-ae79050e7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pareto_fronts(path_and_attack_properties_df, k=10):\n",
    "    ''' Fetches a specified number of Pareto fronts for plotting. '''\n",
    "    pareto_fronts = []\n",
    "    remaining_df = path_and_attack_properties_df.copy()\n",
    "\n",
    "    print('Might wanna grab a coffe here...')\n",
    "    for i in range(1, k + 1):\n",
    "        print(f'Calculating Pareto front {i} of {k}...')\n",
    "        if remaining_df.empty:\n",
    "            print(f'Remaining DataFrame is empty. Stopping at front {i}.')\n",
    "            break\n",
    "        pareto_front = pareto_optimal(remaining_df, 'Success coefficient', 'Expected troop number')\n",
    "        pareto_fronts.append(pareto_front)\n",
    "        remaining_df = remaining_df.drop(pareto_front.index)\n",
    "        print(f'Pareto front {i} calculated. Remaining rows: {len(remaining_df)}')\n",
    "    \n",
    "    return pareto_fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7911c7ad-86e8-4082-bc7b-315fcefde888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pareto_solutions():\n",
    "    ''' Function for executing the program generating Pareto solutions and printing progress. '''\n",
    "    \n",
    "    criteria1 = 'Success coefficient'\n",
    "    criteria2 = 'Expected troop number'\n",
    "    \n",
    "    # Execute functions.\n",
    "    simulation_output_df = load_simulation_output_df()\n",
    "    if not simulation_output_df.empty:\n",
    "        print('Event chains dataframe has been loaded for Pareto optimization.')\n",
    "    else:\n",
    "        print('Could not load event chains dataframe.')\n",
    "        return\n",
    "    path_and_attack_properties_df = process_successful_paths(simulation_output_df)\n",
    "    if not path_and_attack_properties_df.empty:\n",
    "        print('Successful event chains have been processed.')\n",
    "    else:\n",
    "        print('Could not process successful event chains.')\n",
    "        return\n",
    "    pareto_optimals = collect_pareto_solutions(path_and_attack_properties_df, # In this case eqal to first Pareto front.\n",
    "                                               criteria1, criteria2, 10)\n",
    "    if not pareto_optimals.empty:\n",
    "        print('Pareto optimal solutions have been calculated.')\n",
    "    else:\n",
    "        print('Could not calculate Pareto optimal solutions.')\n",
    "        return\n",
    "    pareto_fronts = get_pareto_fronts(path_and_attack_properties_df)\n",
    "    print('Pareto fronts have been calculated')\n",
    "    \n",
    "    # Create dict with info to be used for plotting.\n",
    "    pareto_info_dict = {'path_and_attack_properties_df': path_and_attack_properties_df,\n",
    "                        'pareto_optimals': pareto_optimals,\n",
    "                        'pareto_fronts': pareto_fronts}\n",
    "    if pareto_info_dict:\n",
    "        print('Pareto solutions information dictionary has been created.')\n",
    "    else:\n",
    "        print('Could not create Pareto information dictionary.')\n",
    "        return\n",
    "    \n",
    "    # Save to pickle.\n",
    "    with open('pareto_info_dict.pkl', 'wb') as f:\n",
    "        pickle.dump(pareto_info_dict, f)\n",
    "    print('Pareto solutions information dictionary has been saved to \"pareto_info_dict.pkl\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15385849-9a7f-4c66-a7f7-7c196fa27c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b47f5-6668-41ae-806a-e90d418632fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
